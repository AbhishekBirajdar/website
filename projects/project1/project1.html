<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>Batch Data Processing - AWS, Airflow & Redshift</title>
  <style>
    /* Global Styles */
    * {
      margin: 0;
      padding: 0;
      box-sizing: border-box;
      font-family: Arial, sans-serif;
    }
    body {
      background-color: #000;
      color: #fff;
      line-height: 1.6;
      padding: 3rem 1rem;
    }
    .container {
      max-width: 900px;
      margin: 0 auto;
      background: #111;
      padding: 2rem;
      border-radius: 8px;
      box-shadow: 0px 0px 15px rgba(255, 165, 0, 0.3);
    }
    h1 {
      color: #ffa94d;
      text-align: center;
      margin-bottom: 1rem;
    }
    h2 {
      color: #f47c20;
      margin-top: 1.5rem;
      border-bottom: 2px solid #f47c20;
      padding-bottom: 5px;
    }
    p, ul {
      text-align: justify;
      margin-bottom: 1rem;
    }
    ul {
      padding-left: 1.5rem;
    }
    .back-link {
      display: inline-block;
      margin-bottom: 1rem;
      color: #ffa94d;
      font-weight: bold;
      text-decoration: none;
      border: 1px solid #ffa94d;
      padding: 8px 12px;
      border-radius: 5px;
      transition: background 0.3s, transform 0.2s;
    }
    .back-link:hover {
      background: #ffa94d;
      color: #000;
      transform: scale(1.05);
    }
    img {
      width: 100%;
      border-radius: 8px;
      margin: 1rem 0;
      display: block;
    }
    @media (max-width: 768px) {
      body {
        padding: 2rem 1rem;
      }
      .container {
        padding: 1.5rem;
      }
    }
  </style>
</head>
<body>

  <div class="container">
    <a href="../../projects.html" class="back-link">‚Üê Back to Projects</a>
    <h1>Batch Data Processing of Music Streams Using Airflow & Redshift</h1>
    
    <h2>Executive Summary</h2>
    <p>
      This document outlines the batch data processing workflow implemented using 
      Apache Airflow, Amazon Redshift, and AWS S3. The purpose of this project is to 
      process music streaming data, perform transformations, and generate key insights 
      for reporting and analytics.
    </p>

    <h2>Introduction</h2>
    <p>
      The project involves processing music streaming data using a batch ingestion pipeline. 
      Music streaming data is frequently uploaded to an AWS S3 bucket and must be processed 
      to extract useful analytics. Apache Airflow is used to orchestrate the data ingestion, 
      validation, transformation, and loading into Amazon Redshift for reporting.
    </p>

    <h2>Solution Architecture</h2>
    <p>The solution consists of three main layers:</p>
    <ul>
      <li><strong>Storage Layer:</strong> Data is stored in Amazon S3 in CSV format.</li>
      <li><strong>Orchestration Layer:</strong> Apache Airflow manages the ingestion, validation, and transformation.</li>
      <li><strong>Data Warehouse:</strong> Amazon Redshift stores the processed data for analytics.</li>
    </ul>
    
    <img src="image1.png" alt="Architecture Diagram">

    <h2>Data Pipeline Workflow</h2>
    <p>The batch data pipeline is managed through an Airflow DAG that consists of the following steps:</p>
    <ul>
      <li><strong>Data Ingestion:</strong> Input datasets (songs, users, and streams) are read from S3.</li>
      <li><strong>Validation:</strong> The DAG verifies the required columns are present.</li>
      <li><strong>Transformation:</strong> KPIs such as genre-level insights and hourly engagement metrics are calculated.</li>
      <li><strong>Loading:</strong> The transformed data is ingested into Redshift.</li>
      <li><strong>Archiving:</strong> Processed files are moved to an archive folder.</li>
    </ul>

    <img src="image3.png" alt="Data Pipeline Workflow">

    <h2>Technologies Used</h2>
    <ul>
      <li><strong>Amazon S3:</strong> Acts as the data lake for storing raw and processed data.</li>
      <li><strong>Apache Airflow:</strong> Orchestrates the data pipeline execution.</li>
      <li><strong>Python & Pandas:</strong> Used for data transformation.</li>
      <li><strong>Amazon Redshift:</strong> Data warehouse for analytical reporting.</li>
    </ul>

    <h2>Implementation Details</h2>
    <p>
      The Airflow DAG is implemented with Python operators and hooks to interact with AWS services. 
      Validation results are shared between tasks using XComs, and data transformations are handled 
      using Pandas. The Redshift database schema consists of two primary tables: 
      <code>genre_level_kpis</code> and <code>hourly_kpis</code>. The data is ingested using an 
      UPSERT strategy to ensure freshness.
    </p>

    <img src="image2.png" alt="Airflow DAG Execution">

    <h2>Conclusion & Recommendations</h2>
    <p>
      This project successfully demonstrates the use of AWS services for large-scale data processing. 
      The combination of S3, Airflow, and Redshift allows for efficient batch processing and analysis 
      of music streaming data.
    </p>
    <p><strong>Future Enhancements:</strong></p>
    <ul>
      <li>Implementing incremental data loading for efficiency.</li>
      <li>Utilizing Airflow sensors for real-time event-driven execution.</li>
      <li>Expanding the Redshift schema to include additional analytics use cases.</li>
    </ul>
  </div>

</body>
</html>
